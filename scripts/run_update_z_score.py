# scripts/run_update_z_score.py

import sys
import os
import argparse
import time
import pandas as pd
from sqlalchemy.orm import Session

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__)) 
project_root = os.path.dirname(current_dir)              
sys.path.append(project_root)

# DB ë° ëª¨ë“ˆ ì„í¬íŠ¸
from src.database.connection import SessionLocal
from src.modules.dtm_initializer import DTMInitializer
from src.modules.tf_idf_updater import TFIDFUpdater
from src.modules.z_score_updater import ZScoreUpdater

from src.utils.common import load_yaml
from src.utils.logger import setup_experiment_logger 
from src.utils.visualizer import plot_z_score_distribution
from src.database.crud import get_all_dtm_for_viz


# ì „ì—­ ë¡œê±° ì„¤ì •
logger = setup_experiment_logger("DB_STAT_PIPELINE")

def main():
    """
    [Main Execution Pipeline]
    1. í™˜ê²½ ì„¤ì • ë¡œë“œ (YAML/Argparse)
    2. DB ì´ˆê¸°í™” ë° ë„ë©”ì¸ ìŠ¤ìº” (Phase 1)
    3. TF-IDF ê³„ì‚° ë° ì—…ë°ì´íŠ¸ (Phase 2)
    4. Z-Score ì‚°ì¶œ ë° ì •ê·œí™” (Phase 3)
    """
    
    # 1. Argument Parsing
    parser = argparse.ArgumentParser(description="DB-based TF-IDF & Z-Score Update Pipeline")
    parser.add_argument("--config", type=str, default="configs/base_config.yaml", help="Path to config file")
    args = parser.parse_args()

    # 2. Config & Path ë¡œë“œ (ê¸°ì¡´ ìŠ¤íƒ€ì¼ ìœ ì§€)
    model_name = "klue/roberta-base"
    train_data_root = "data/train_data"

    if os.path.exists(args.config):
        try:
            config = load_yaml(args.config)
            if 'path' in config:
                train_data_root = config['path'].get('train_data_root', train_data_root)
            if 'train' in config:
                model_name = config['train'].get('model_name', model_name)
            logger.info(f"[Config] Loaded - Model: {model_name}, Data Root: {train_data_root}")
        except Exception as e:
            logger.warning(f"[Config] Failed to load config, using defaults: {e}")

    # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    if not os.path.isabs(train_data_root):
        train_data_root = os.path.join(project_root, train_data_root)

    # 3. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    logger.info("=" * 60)
    logger.info("ğŸš€ Starting DB-based Statistical Analysis Pipeline")
    logger.info("=" * 60)
    
    start_all = time.time()
    session: Session = SessionLocal()
    
    try:
        # --- [Phase 1] DTM Initialization & Data Scanning ---
        logger.info("[Phase 1] Initializing Tables & Scanning train_data...")
        p1_start = time.time()
        initializer = DTMInitializer(session, model_name=model_name)
        initializer.initialize_and_scan(train_data_root)
        session.commit() # íŠ¸ëœì­ì…˜ í™•ì •
        logger.info(f"âœ… Phase 1 Completed ({time.time() - p1_start:.2f}s)")

        # --- [Phase 2] Global TF-IDF Calculation ---
        logger.info("[Phase 2] Computing Global TF-IDF Scores...")
        p2_start = time.time()
        tfidf_up = TFIDFUpdater(session)
        tfidf_up.update_tfidf_scores()
        session.commit() # íŠ¸ëœì­ì…˜ í™•ì •
        logger.info(f"âœ… Phase 2 Completed ({time.time() - p2_start:.2f}s)")

        # --- [Phase 3] Local Z-Score Normalization ---
        logger.info("[Phase 3] Normalizing Z-Scores per Domain...")
        p3_start = time.time()
        z_up = ZScoreUpdater(session)
        z_up.update_z_scores()
        session.commit() # íŠ¸ëœì­ì…˜ í™•ì •
        logger.info(f"âœ… Phase 3 Completed ({time.time() - p3_start:.2f}s)")

        total_elapsed = time.time() - start_all
        logger.info("=" * 60)
        logger.info(f"âœ¨ Pipeline Finished Successfully! (Total: {total_elapsed:.2f}s)")
        logger.info("=" * 60)

    except Exception as e:
        session.rollback() # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëª¨ë“  ë³€ê²½ì‚¬í•­ ë˜ëŒë¦¼
        logger.critical(f"âŒ Pipeline Failed due to Error: {e}", exc_info=True)
        sys.exit(1)
        
    finally:
        session.close() # DB ì„¸ì…˜ ë°˜ë‚©

    # 4. Visualization
    logger.info("[Phase 4] Generating Statistical Distributions...")
    try:        
        # 1. DBì—ì„œ ë°ì´í„° ë¡œë“œ (yield_perë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ ë¦¬ìŠ¤íŠ¸í™”)
        # ì‹œê°í™”ì— í•„ìš”í•œ 2ê°œ ì»¬ëŸ¼(z_score, is_sensitive_label)ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        session_viz = SessionLocal() # ìƒˆ ì„¸ì…˜ì„ ì—´ê±°ë‚˜ ê¸°ì¡´ ë¡œì§ ìœ ì§€
        viz_data_gen = get_all_dtm_for_viz(session_viz, batch_size=10000)
        
        # 2. DataFrame ë³€í™˜ (ëª¨ë“  ìƒ˜í”Œì„ ë©”ëª¨ë¦¬ì— ì ì¬)
        viz_df = pd.DataFrame(viz_data_gen)
        
        if not viz_df.empty:
            # 3. ì‹œê°í™” ì‹¤í–‰ (ê·¸ë¦¼ ê·¸ë¦¬ê¸° ì „ìš© í•¨ìˆ˜ í˜¸ì¶œ)
            report_dir = os.path.join(train_data_root, "reports")
            plot_z_score_distribution(viz_df, report_dir)
            logger.info(f"âœ… Phase 4 Completed. Check {report_dir} for results.")
        else:
            logger.warning("âš ï¸ No data found in DomainTermMatrix to plot.")
            
    except Exception as e:
        logger.error(f"âŒ Visualization failed: {e}")
    finally:
        session_viz.close()

if __name__ == "__main__":
    main()