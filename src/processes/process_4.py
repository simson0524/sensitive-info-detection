# src/processes/process_4.py

import torch
import os
import logging
from datetime import datetime
from torch.utils.data import DataLoader

# Modules
from src.modules.ner_evaluator import Evaluator
from src.models.ner_roberta import RobertaNerModel

# Database
from src.database.connection import db_manager
from src.database import crud

# Utils
from src.utils.common import ensure_dir, save_logs_to_csv

def run_process_4(config: dict, context: dict):
    """
    [Process 4] ëª¨ë¸ ë³´ì™„ ì¶”ë¡  ë° Hybrid ê²€ì¦ í”„ë¡œì„¸ìŠ¤
    
    1. ê·œì¹™(ì‚¬ì „/Regex)ì´ ì°¾ì€ ê²°ê³¼ë¥¼ DBì—ì„œ ë¡œë“œí•˜ì—¬ ë©”ëª¨ë¦¬ì— ë§¤í•‘.
    2. í•™ìŠµëœ Best Modelë¡œ ì „ì²´ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•´ ì¶”ë¡  ìˆ˜í–‰.
    3. ëª¨ë¸ ê²°ê³¼ì™€ ê·œì¹™ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ìœ í˜• ë¶„ë¥˜ ë° í†µê³„ ì‚°ì¶œ:
       - Double Check: ê·œì¹™ë„ ì°¾ê³  ëª¨ë¸ë„ ì°¾ìŒ (ì‹ ë¢°ë„ ë†’ìŒ)
       - Model Complement: ê·œì¹™ì€ ëª» ì°¾ì•˜ëŠ”ë° ëª¨ë¸ì´ ì°¾ìŒ (ëª¨ë¸ì˜ ê¸°ì—¬ë„)
       - Rule Only: ê·œì¹™ì€ ì°¾ì•˜ëŠ”ë° ëª¨ë¸ì€ ëª» ì°¾ìŒ (ëª¨ë¸ì˜ í•œê³„)
    4. ë¶„ì„ ê²°ê³¼ ë° ë¡œê·¸ DB ì €ì¥ & CSV ì¶”ì¶œ.
    """
    
    # ==============================================================================
    # [Step 1] ì„¤ì • ë° ë¡œê±° ì´ˆê¸°í™”
    # ==============================================================================
    experiment_code = context['experiment_code']
    device = context['device']
    preprocessor = context['preprocessor']
    
    path_conf = config['path']
    train_conf = config['train']

    logger = logging.getLogger(experiment_code)
    logger.info(f"ğŸš€ [Process 4] Start Hybrid Inference & Analysis")

    # ==============================================================================
    # [Step 2] ê·œì¹™ ê¸°ë°˜ íƒì§€ ê²°ê³¼ ë¡œë“œ (Process 2 & 3)
    # ==============================================================================
    logger.info("Loading Rule-based detection results from DB...")
    
    rule_hits = {}
    
    with db_manager.get_db() as session:
        for proc_code in ["process_2", "process_3"]:
            logs = crud.get_inference_sentences(session, experiment_code, proc_code, 1)
            for log in logs:
                sid = log['sentence_id']
                if sid not in rule_hits:
                    rule_hits[sid] = {}
                
                res = log.get('sentence_inference_result', {})
                results_list = res.get('inference_results', [])
                
                for r in results_list:
                    if r.get('match_result') in ['hit', 'prediction']:
                        word = r['word']
                        label = r['label']
                        rule_hits[sid][word] = label

    logger.info(f"Loaded rule hits for {len(rule_hits)} sentences.")

    # ==============================================================================
    # [Step 3] Best Model ë¡œë“œ
    # ==============================================================================
    logger.info("Loading Best Model from Checkpoint...")
    
    encoder = context['model'].encoder 
    num_labels = len(preprocessor.ner_label2id)
    
    best_model = RobertaNerModel(
        encoder=encoder,
        num_classes=num_labels,
        use_focal=False 
    ).to(device)
    
    ckpt_path = os.path.join(
        path_conf['checkpoint_dir'], experiment_code, f"{experiment_code}_best.pt"
    )
    
    if os.path.exists(ckpt_path):
        best_model.load_state_dict(torch.load(ckpt_path, map_location=device))
        logger.info(f"âœ… Loaded weights from {ckpt_path}")
    else:
        logger.warning(f"âš ï¸ Checkpoint not found at {ckpt_path}. Using current model state.")
        best_model = context['model']

    # ==============================================================================
    # [Step 4] ì¶”ë¡  ë° ë¹„êµ ë¶„ì„ (Hybrid Logic)
    # ==============================================================================
    evaluator = Evaluator(
        best_model, 
        device, 
        preprocessor.tokenizer, 
        preprocessor.ner_id2label 
    )

    result = evaluator.evaluate(context['valid_loader'], mode="test")
    raw_logs = result['logs']

    stats = {
        "double_check": 0, "model_complement": 0, "rule_only": 0, "total_model_detected": 0
    }

    processed_logs = []

    for log in raw_logs:
        sid = log['sentence_id']
        model_results = log['sentence_inference_result']['inference_results']
        rule_findings = rule_hits.get(sid, {}).copy() 
        
        # 1. ëª¨ë¸ íƒì§€ ê²°ê³¼ ìˆœíšŒ
        for entity in model_results:
            word = entity['word']
            if word in rule_findings:
                entity['hybrid_status'] = "Double Check"
                stats['double_check'] += 1
                rule_findings.pop(word, None)
            else:
                entity['hybrid_status'] = "Model Complement"
                stats['model_complement'] += 1
            stats['total_model_detected'] += 1
            
        # 2. Rule Only ê³„ì‚°
        for r_word, r_label in rule_findings.items():
            stats['rule_only'] += 1
            model_results.append({
                "word": r_word,
                "label": r_label,
                "start": -1, 
                "end": -1,
                "hybrid_status": "Rule Only (Model Missed)"
            })
        
        log['sentence_inference_result']['inference_results'] = model_results
        log['sentence_inference_result']['entity_count'] = len(model_results)
        processed_logs.append(log)

    # ë¹„ìœ¨ ê³„ì‚°
    total_detections = stats['double_check'] + stats['model_complement'] + stats['rule_only']
    if total_detections > 0:
        stats['ratio_double_check'] = round(stats['double_check'] / total_detections, 4)
        stats['ratio_complement'] = round(stats['model_complement'] / total_detections, 4)
        stats['ratio_rule_only'] = round(stats['rule_only'] / total_detections, 4)
    else:
        stats.update({'ratio_double_check': 0, 'ratio_complement': 0, 'ratio_rule_only': 0})

    logger.info(f"ğŸ“Š Hybrid Analysis Result: {stats}")

    # ==============================================================================
    # [Step 5] DB ì €ì¥ ë° CSV ì¶”ì¶œ
    # ==============================================================================
    
    # CSV ì €ì¥ ê²½ë¡œ ìƒì„±
    log_save_dir = os.path.join(path_conf['log_dir'], experiment_code)
    ensure_dir(log_save_dir)

    with db_manager.get_db() as session:
        # 5-1. ê²°ê³¼ ìš”ì•½ ì €ì¥
        crud.create_process_result(session, {
            "experiment_code": experiment_code,
            "process_code": "process_4", 
            "process_epoch": 1,
            "process_start_time": datetime.now(), 
            "process_end_time": result.get('end_time', datetime.now()),
            "process_duration": result['metrics'].get('duration', 0.0),
            "process_results": {
                "hybrid_stats": stats,
                "base_metrics": result['metrics']
            }
        })

        # 5-2. ë¬¸ì¥ ë¡œê·¸ ì €ì¥ (Bulk Insert)
        # FK ì£¼ì…
        for log in processed_logs:
            log['experiment_code'] = experiment_code
            log['process_code'] = "process_4"
            log['process_epoch'] = 1
        
        crud.bulk_insert_inference_sentences(session, processed_logs)
        logger.info(f"Saved {len(processed_logs)} hybrid inference logs to DB.")
        
        # 5-3. [NEW] CSV íŒŒì¼ ì¶”ì¶œ
        csv_file_name = f"{experiment_code}_process_4_1_inference_sentences.csv"
        csv_file_path = os.path.join(log_save_dir, csv_file_name)
        
        save_logs_to_csv(processed_logs, csv_file_path)
        logger.info(f"Saved CSV log to {csv_file_path}")

    logger.info("[Process 4] Completed.")
    return context