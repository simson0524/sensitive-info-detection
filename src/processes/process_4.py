# src/processes/process_4.py

import torch
import os
import logging
from datetime import datetime
from torch.utils.data import DataLoader

# Modules
from src.modules.ner_evaluator import Evaluator
from src.models.ner_roberta import RobertaNerModel

# Database
from src.database.connection import db_manager
from src.database import crud

def run_process_4(config: dict, context: dict):
    """
    [Process 4] ëª¨ë¸ ë³´ì™„ ì¶”ë¡  ë° Hybrid ê²€ì¦ í”„ë¡œì„¸ìŠ¤
    
    1. ê·œì¹™(ì‚¬ì „/Regex)ì´ ì°¾ì€ ê²°ê³¼ë¥¼ DBì—ì„œ ë¡œë“œí•˜ì—¬ ë©”ëª¨ë¦¬ì— ë§¤í•‘.
    2. í•™ìŠµëœ Best Modelë¡œ ì „ì²´ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•´ ì¶”ë¡  ìˆ˜í–‰.
    3. ëª¨ë¸ ê²°ê³¼ì™€ ê·œì¹™ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ìœ í˜• ë¶„ë¥˜ ë° í†µê³„ ì‚°ì¶œ:
       - Double Check: ê·œì¹™ë„ ì°¾ê³  ëª¨ë¸ë„ ì°¾ìŒ (ì‹ ë¢°ë„ ë†’ìŒ)
       - Model Complement: ê·œì¹™ì€ ëª» ì°¾ì•˜ëŠ”ë° ëª¨ë¸ì´ ì°¾ìŒ (ëª¨ë¸ì˜ ê¸°ì—¬ë„)
       - Rule Only: ê·œì¹™ì€ ì°¾ì•˜ëŠ”ë° ëª¨ë¸ì€ ëª» ì°¾ìŒ (ëª¨ë¸ì˜ í•œê³„)
    4. ë¶„ì„ ê²°ê³¼ ë° ë¡œê·¸ DB ì €ì¥.
    """
    
    # ==============================================================================
    # [Step 1] ì„¤ì • ë° ë¡œê±° ì´ˆê¸°í™”
    # ==============================================================================
    experiment_code = context['experiment_code']
    device = context['device']
    preprocessor = context['preprocessor']
    
    path_conf = config['path']
    train_conf = config['train']

    logger = logging.getLogger(experiment_code)
    logger.info(f"ğŸš€ [Process 4] Start Hybrid Inference & Analysis")

    # ==============================================================================
    # [Step 2] ê·œì¹™ ê¸°ë°˜ íƒì§€ ê²°ê³¼ ë¡œë“œ (Process 2 & 3)
    # ==============================================================================
    logger.info("Loading Rule-based detection results from DB...")
    
    # êµ¬ì¡°: rule_hits[sentence_id] = { "ë‹¨ì–´": "ë¼ë²¨", ... }
    rule_hits = {}
    
    with db_manager.get_db() as session:
        # Process 2 (Dictionary) & Process 3 (Regex) ê²°ê³¼ ëª¨ë‘ ì¡°íšŒ
        for proc_code in ["process_2", "process_3"]:
            # generatorë¥¼ í†µí•´ ëŒ€ìš©ëŸ‰ ë¡œê·¸ ìˆœíšŒ (ë©”ëª¨ë¦¬ ì ˆì•½)
            logs = crud.get_inference_sentences(session, experiment_code, proc_code, 1)
            
            for log in logs:
                sid = log['sentence_id']
                if sid not in rule_hits:
                    rule_hits[sid] = {}
                
                # JSON íŒŒì‹±
                res = log.get('sentence_inference_result', {})
                results_list = res.get('inference_results', [])
                
                for r in results_list:
                    # 'hit' (ì •íƒ) ë˜ëŠ” 'prediction' (Testëª¨ë“œ íƒì§€) ì¸ ê²ƒë§Œ ìˆ˜ì§‘
                    # ì˜¤íƒ(wrong)ì´ë‚˜ ë¯¸íƒ(mismatch)ì€ ì œì™¸
                    if r.get('match_result') in ['hit', 'prediction']:
                        word = r['word']
                        label = r['label']
                        rule_hits[sid][word] = label

    logger.info(f"Loaded rule hits for {len(rule_hits)} sentences.")

    # ==============================================================================
    # [Step 3] Best Model ë¡œë“œ
    # ==============================================================================
    logger.info("Loading Best Model from Checkpoint...")
    
    # ëª¨ë¸ ê»ë°ê¸° ìƒì„± (ê¸°ì¡´ ì¸ì½”ë” ì¬ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½)
    encoder = context['model'].encoder 
    num_labels = len(preprocessor.ner_label2id)
    
    best_model = RobertaNerModel(
        encoder=encoder,
        num_classes=num_labels,
        use_focal=False # ì¶”ë¡ ì—” focal loss ë¶ˆí•„ìš”
    ).to(device)
    
    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    ckpt_path = os.path.join(
        path_conf['checkpoint_dir'], experiment_code, f"{experiment_code}_best.pt"
    )
    
    if os.path.exists(ckpt_path):
        best_model.load_state_dict(torch.load(ckpt_path, map_location=device))
        logger.info(f"âœ… Loaded weights from {ckpt_path}")
    else:
        logger.warning(f"âš ï¸ Checkpoint not found at {ckpt_path}. Using current model state.")
        best_model = context['model'] # Fallback

    # ==============================================================================
    # [Step 4] ì¶”ë¡  ë° ë¹„êµ ë¶„ì„ (Hybrid Logic)
    # ==============================================================================
    evaluator = Evaluator(
        best_model, 
        device, 
        preprocessor.tokenizer, 
        preprocessor.ner_id2label 
    )

    # ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì¶”ë¡  (mode='test'ë¡œ í•˜ì—¬ ìˆœìˆ˜ ì˜ˆì¸¡ê°’ë§Œ ë°›ìŒ)
    # GT ë¹„êµëŠ” ì—¬ê¸°ì„œ ë³„ë„ë¡œ ìˆ˜í–‰í•˜ì§€ ì•Šê³ , Ruleê³¼ì˜ ë¹„êµì— ì§‘ì¤‘í•©ë‹ˆë‹¤.
    result = evaluator.evaluate(context['valid_loader'], mode="test")
    raw_logs = result['logs'] # Evaluatorê°€ ë§Œë“  ê¸°ë³¸ ë¡œê·¸ (List[Dict])

    # í†µê³„ ì§‘ê³„ ë³€ìˆ˜ ì´ˆê¸°í™”
    stats = {
        "double_check": 0,      # ê·œì¹™ O, ëª¨ë¸ O
        "model_complement": 0,  # ê·œì¹™ X, ëª¨ë¸ O
        "rule_only": 0,         # ê·œì¹™ O, ëª¨ë¸ X
        "total_model_detected": 0
    }

    processed_logs = []

    for log in raw_logs:
        sid = log['sentence_id']
        
        # ëª¨ë¸ì´ ì°¾ì€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (Evaluatorê°€ ë§Œë“  êµ¬ì¡°)
        # inference_results: [{'word': 'í™ê¸¸ë™', 'label': 'ì¸ë¬¼', ...}]
        model_results = log['sentence_inference_result']['inference_results']
        
        # í•´ë‹¹ ë¬¸ì¥ì˜ ê·œì¹™ íƒì§€ ê²°ê³¼ (Dict: {word: label})
        rule_findings = rule_hits.get(sid, {}).copy() # popì„ ìœ„í•´ ë³µì‚¬ë³¸ ì‚¬ìš©
        
        # 1. ëª¨ë¸ íƒì§€ ê²°ê³¼ ìˆœíšŒ (Double Check vs Complement í™•ì¸)
        for entity in model_results:
            word = entity['word']
            
            if word in rule_findings:
                # ê·œì¹™ë„ ì°¾ê³  ëª¨ë¸ë„ ì°¾ìŒ -> Double Check
                entity['hybrid_status'] = "Double Check"
                stats['double_check'] += 1
                # í™•ì¸ëœ ê·œì¹™ ê²°ê³¼ëŠ” ì œê±° (ë‚˜ì¤‘ì— Rule Only ê³„ì‚° ìœ„í•¨)
                rule_findings.pop(word, None)
            else:
                # ê·œì¹™ì€ ëª» ì°¾ì•˜ëŠ”ë° ëª¨ë¸ì´ ì°¾ìŒ -> Model Complement
                entity['hybrid_status'] = "Model Complement"
                stats['model_complement'] += 1
            
            stats['total_model_detected'] += 1
            
        # 2. Rule Only ê³„ì‚° (ëª¨ë¸ ê²°ê³¼ì—ëŠ” ì—†ì§€ë§Œ ê·œì¹™ì—ëŠ” ë‚¨ì•„ìˆëŠ” ê²ƒ)
        for r_word, r_label in rule_findings.items():
            stats['rule_only'] += 1
            
            # ë¡œê·¸ì— ì¶”ê°€ (ì„ íƒ ì‚¬í•­: ëª¨ë¸ì´ ë†“ì¹œ ê²ƒë„ ê¸°ë¡í•˜ì—¬ ì™„ë²½í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼ ìƒì„±)
            model_results.append({
                "word": r_word,
                "label": r_label,
                "start": -1, # ìœ„ì¹˜ ì •ë³´ëŠ” ì—­ì¶”ì  ì–´ë ¤ìš°ë¯€ë¡œ -1 ë˜ëŠ” ìƒëµ
                "end": -1,
                "hybrid_status": "Rule Only (Model Missed)"
            })
        
        # ì—…ë°ì´íŠ¸ëœ ë¡œê·¸(hybrid_status í¬í•¨) ì €ì¥
        log['sentence_inference_result']['inference_results'] = model_results
        log['sentence_inference_result']['entity_count'] = len(model_results)
        processed_logs.append(log)

    # -------------------------------------------------------------
    # ë¹„ìœ¨(Ratio) ê³„ì‚°
    # -------------------------------------------------------------
    total_detections = stats['double_check'] + stats['model_complement'] + stats['rule_only']
    if total_detections > 0:
        stats['ratio_double_check'] = round(stats['double_check'] / total_detections, 4)
        stats['ratio_complement'] = round(stats['model_complement'] / total_detections, 4)
        stats['ratio_rule_only'] = round(stats['rule_only'] / total_detections, 4)
    else:
        stats.update({'ratio_double_check': 0, 'ratio_complement': 0, 'ratio_rule_only': 0})

    logger.info(f"ğŸ“Š Hybrid Analysis Result: {stats}")

    # ==============================================================================
    # [Step 5] DB ì €ì¥
    # ==============================================================================
    with db_manager.get_db() as session:
        # 5-1. ê²°ê³¼ ìš”ì•½ ì €ì¥
        crud.create_process_result(session, {
            "experiment_code": experiment_code,
            "process_code": "process_4", 
            "process_epoch": 1,
            "process_start_time": datetime.now(), # ê·¼ì‚¬ì¹˜
            "process_end_time": result.get('end_time', datetime.now()),
            "process_duration": result['metrics'].get('duration', 0.0),
            
            # ë¶„ì„ í†µê³„ ë° ëª¨ë¸ ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ í•¨ê»˜ ì €ì¥
            "process_results": {
                "hybrid_stats": stats,
                "base_metrics": result['metrics'] # ëª¨ë¸ ìì²´ ì„±ëŠ¥ ì§€í‘œ (Loss ë“±)
            }
        })

        # 5-2. ë¬¸ì¥ ë¡œê·¸ ì €ì¥ (Hybrid Status í¬í•¨)
        for log in processed_logs:
            log['experiment_code'] = experiment_code
            log['process_code'] = "process_4"
            log['process_epoch'] = 1
        
        crud.bulk_insert_inference_sentences(session, processed_logs)
        logger.info(f"Saved {len(processed_logs)} hybrid inference logs to DB.")

    logger.info("[Process 4] Completed.")
    return context