# src/processes/process_0.py

import torch
import os
from torch.utils.data import DataLoader
from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup
from torch.optim import AdamW
from sklearn.model_selection import train_test_split

# Modules: Nerëª¨ë¸ê³¼ í•´ë‹¹ ëª¨ë¸ì— ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê¸° ìœ„í•œ ì „ì²˜ë¦¬ ëª¨ë“ˆ
from src.modules.ner_preprocessor import NerPreprocessor
from src.models.ner_roberta import RobertaNerModel

# Utils: ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
from src.utils.common import set_seed
from src.utils.logger import setup_experiment_logger

def run_process_0(config: dict) -> dict:
    """
    [Process 0] í•™ìŠµ í™˜ê²½ ë° ê°ì²´ ì´ˆê¸°í™” í”„ë¡œì„¸ìŠ¤ (Setup Phase)
    
    ì´ í•¨ìˆ˜ì˜ ì—­í• :
    1. ë¼ë²¨ ë§µ ì„ íƒ: data_category(ê°œì¸/ê¸°ë°€)ì— ë”°ë¼ ì ì ˆí•œ ë¼ë²¨ ë§µì„ ë¡œë“œí•©ë‹ˆë‹¤.
    2. ë°ì´í„° ë¡œë“œ: í•˜ë‚˜ì˜ ì›ë³¸ í´ë”ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ Train/Validë¡œ ìë™ ë¶„í• í•©ë‹ˆë‹¤.
    3. ëª¨ë¸ ì´ˆê¸°í™”: ì„¤ì •ëœ ì•„í‚¤í…ì²˜(RoBERTa ë“±)ë¡œ ëª¨ë¸ ê»ë°ê¸°ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    4. ê°€ì¤‘ì¹˜ ë¡œë“œ: ë§Œì•½ ì´ì–´ì„œ í•™ìŠµ(Resume)í•´ì•¼ í•œë‹¤ë©´ ì €ì¥ëœ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    5. ë„êµ¬ ì¤€ë¹„: Optimizer, Scheduler ë“±ì„ ì¤€ë¹„í•˜ì—¬ íŒ¨í‚¤ì§•(Context)í•©ë‹ˆë‹¤.
    
    Args:
        config (dict): experiment_config.yamlì—ì„œ ë¡œë“œí•œ ì„¤ì •ê°’
        
    Returns:
        dict: í•™ìŠµì— í•„ìš”í•œ ëª¨ë“  ê°ì²´ê°€ ë‹´ê¸´ Context
    """
    
    # ==============================================================================
    # [Step 1] ì„¤ì • ë¡œë“œ ë° ë¡œê±° ì´ˆê¸°í™”
    # ==============================================================================
    exp_conf = config['experiment']
    train_conf = config['train']
    path_conf = config['path']
    label_settings = config['label_settings'] # [NEW] base_configì—ì„œ ë¡œë“œëœ ë¼ë²¨ ì„¤ì •
    target_device = train_conf['device']
    
    experiment_code = exp_conf['experiment_code']
    run_mode = exp_conf.get('run_mode', 'train') # 'train' or 'test'
    
    # ë¡œê±° ìƒì„± (ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ íŒŒì¼ê³¼ í•¨ê»˜ ìƒì„±)
    logger = setup_experiment_logger(experiment_code, path_conf['log_dir'])
    logger.info(f"ğŸ› ï¸ [Process 0] Initializing Experiment: {experiment_code} (Mode: {run_mode.upper()})")

    # ì¬í˜„ì„±ì„ ìœ„í•´ ëœë¤ ì‹œë“œ ê³ ì •
    set_seed(train_conf.get('seed', 42))
    device = torch.device(target_device if torch.cuda.is_available() else 'cpu')

    # [í•µì‹¬] ë°ì´í„° ì¹´í…Œê³ ë¦¬ì— ë”°ë¥¸ ë¼ë²¨ ë§µ ì„ íƒ
    data_category = exp_conf.get('data_category', 'personal_data')
    
    if data_category not in label_settings:
        raise ValueError(f"âŒ Unknown data_category: '{data_category}'. Check config files.")
        
    # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ë¼ë²¨ ë§µ ê°€ì ¸ì˜¤ê¸° (ì˜ˆ: personal_data -> {'ì¼ë°˜':0, 'ê°œì¸':1, 'ì¤€ì‹ë³„':2})
    current_label_map = label_settings[data_category]['label_map']
    
    logger.info(f"ğŸ¯ Target Category: {data_category}")
    logger.info(f"ğŸ·ï¸  Active Label Map: {current_label_map}")


    # ==============================================================================
    # [Step 2] ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¡œë“œ (Data Preparation)
    # ==============================================================================
    logger.info("Step 1: Loading Data & Splitting Train/Valid...")
    
    # HuggingFace Tokenizer ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(train_conf['model_name'])
    
    # 2-1. ì „ì²˜ë¦¬ê¸°(Preprocessor) ì´ˆê¸°í™”
    # ì„ íƒëœ ë¼ë²¨ ë§µ(current_label_map)ì„ ì£¼ì…í•˜ì—¬ BIO íƒœê¹… ê·œì¹™ì„ ìƒì„±í•©ë‹ˆë‹¤.
    preprocessor = NerPreprocessor(
        tokenizer=tokenizer, 
        max_len=train_conf['max_len'], 
        label2id=current_label_map # [ìˆ˜ì •ë¨] ë™ì ìœ¼ë¡œ ì„ íƒëœ ë§µ ì‚¬ìš©
    )
    
    # 2-2. ì „ì²´ All(train, valid) Data + Test Dataë¡œë“œ
    all_samples, all_annos = preprocessor.load_data(path_conf['data_dir'])
    
    total_count = len(all_samples)
    if total_count == 0:
        # í•™ìŠµ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë” ì´ìƒ ì§„í–‰í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì—ëŸ¬ ë°œìƒ
        raise ValueError(f"âŒ No data found in {path_conf['data_dir']}")

    # 2-3. Train / Valid ìë™ ë¶„í• 
    val_ratio = train_conf.get('validation_split', 0.2)
    all_ids = list(all_samples.keys())
    
    train_ids, valid_ids = train_test_split(
        all_ids, 
        test_size=val_ratio, 
        random_state=train_conf.get('seed', 42), 
        shuffle=True
    )
    
    # í•™ìŠµ ë°ì´í„°
    train_samples = {uid: all_samples[uid] for uid in train_ids}
    train_annos = {uid: all_annos[uid] for uid in train_ids}
    
    # ê²€ì¦ ë°ì´í„°
    valid_samples = {uid: all_samples[uid] for uid in valid_ids}
    valid_annos = {uid: all_annos[uid] for uid in valid_ids}

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    if path_conf['test_data_dir']:
        test_samples, test_annos = preprocessor.load_data(path_conf['test_data_dir'])
    else:
        test_samples = valid_samples
        test_annos = valid_annos

    logger.info(f"ğŸ“Š Data Split Result: Total({total_count}) -> Train({len(train_ids)}) / Valid({len(valid_ids)})")
    logger.info(f"ğŸ“Š Test Data Result: Test({len(test_annos)})")

    # 2-4. Dataset ê°ì²´ ìƒì„±
    # data_categoryë¥¼ ì „ë‹¬í•˜ì—¬ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” ë¼ë²¨ë§Œ í•„í„°ë§í•˜ë„ë¡ í•¨
    logger.info("Creating Train Dataset...")
    train_dataset = preprocessor.create_dataset(train_samples, train_annos, data_category=data_category)
    
    logger.info("Creating Valid Dataset...")
    valid_dataset = preprocessor.create_dataset(valid_samples, valid_annos, data_category=data_category)

    logger.info("Creating Test Dataset...")
    test_dataset = preprocessor.create_dataset(test_samples, test_annos, data_category=data_category)
    
    # 2-5. DataLoader ìƒì„±
    train_loader = DataLoader(train_dataset, batch_size=train_conf['batch_size'], shuffle=True, collate_fn=smart_collate_fn)
    valid_loader = DataLoader(valid_dataset, batch_size=train_conf['batch_size'], shuffle=False, collate_fn=smart_collate_fn)
    test_loader  = DataLoader(test_dataset, batch_size=train_conf['batch_size'], shuffle=False, collate_fn=smart_collate_fn)


    # ==============================================================================
    # [Step 3] ëª¨ë¸ ì´ˆê¸°í™” ë° ê°€ì¤‘ì¹˜ ë¡œë“œ (Model Setup)
    # ==============================================================================
    logger.info("Step 2: Building Model & Loading Weights...")
    
    encoder = AutoModel.from_pretrained(train_conf['model_name'])
    num_labels = len(preprocessor.ner_label2id) # BIO íƒœê·¸ ê°œìˆ˜ (ìë™ ê³„ì‚°ë¨)
    
    # Custom NER ëª¨ë¸ ìƒì„± (ì¶œë ¥ í´ë˜ìŠ¤ ê°œìˆ˜ëŠ” num_labelsì— ë§ì¶°ì§)
    model = RobertaNerModel(
        encoder=encoder,
        num_classes=num_labels,
        use_focal=train_conf.get('use_focal', False)
    ).to(device)

    # --------------------------------------------------------------------------
    # [ì¤‘ìš”] ê°€ì¤‘ì¹˜ ë¡œë“œ í†µí•© ë¡œì§ (Train/Test ê³µí†µ)
    # run_modeì— ë”°ë¼ ì ì ˆí•œ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¥¼ ì„ íƒí•˜ì—¬ ë¡œë“œí•©ë‹ˆë‹¤.
    # --------------------------------------------------------------------------
    target_ckpt_path = None
    
    if run_mode == 'test':
        # Test ëª¨ë“œ: inference_checkpoint ë¡œë“œ (í•„ìˆ˜)
        target_ckpt_path = path_conf.get('inference_checkpoint')
        if not target_ckpt_path:
            logger.warning("âš ï¸ [Test Mode] 'inference_checkpoint' is not set in config!")
    else:
        # Train ëª¨ë“œ: resume_checkpoint ë¡œë“œ (ì„ íƒ)
        target_ckpt_path = path_conf.get('resume_checkpoint')

    # ê²½ë¡œê°€ ìœ íš¨í•˜ë©´ ê°€ì¤‘ì¹˜ ë¡œë“œ ìˆ˜í–‰
    if target_ckpt_path and os.path.exists(target_ckpt_path):
        logger.info(f"ğŸ“¥ Loading Weights from: {target_ckpt_path}")
        try:
            state_dict = torch.load(target_ckpt_path, map_location=device)
            model.load_state_dict(state_dict)
            logger.info("âœ… Weights loaded successfully.")
        except Exception as e:
            logger.error(f"âŒ Failed to load checkpoint: {e}")
            raise e
    else:
        if run_mode == 'test':
            logger.warning("âš ï¸ Running TEST mode with RANDOM weights (Checkpoint not found).")
        else:
            logger.info("ğŸ†• Initialized model with Base Weights (No resume checkpoint found).")

    # ==============================================================================
    # [Step 4] í•™ìŠµ ë„êµ¬ ì„¤ì • (Optimizer & Scheduler)
    # ==============================================================================
    optimizer = AdamW(model.parameters(), lr=float(train_conf['learning_rate']))
    
    total_steps = len(train_loader) * train_conf['epochs']
    scheduler = get_linear_schedule_with_warmup(
        optimizer, 
        num_warmup_steps=int(total_steps * 0.1),
        num_training_steps=total_steps
    )

    logger.info("âœ… [Process 0] Setup Completed Successfully.")

    # ==============================================================================
    # [Step 5] Context íŒ¨í‚¤ì§• ë° ë°˜í™˜
    # ==============================================================================
    context = {
        "experiment_code": experiment_code,
        "device": device,
        "model": model,
        "optimizer": optimizer,
        "scheduler": scheduler,
        "train_loader": train_loader,
        "valid_loader": valid_loader,
        "test_loader": test_loader,
        "preprocessor": preprocessor, 
        "train_dataset": train_dataset, 
        "valid_dataset": valid_dataset,
        "test_dataset": test_dataset,
        "best_epoch": 0
    }
    
    return context


import torch

def smart_collate_fn(batch):
    keys = batch[0].keys()
    output = {}

    for key in keys:
        sample = batch[0][key]

        # [Case 1] í…ì„œì¸ ê²½ìš° -> Stack
        if isinstance(sample, torch.Tensor):
            output[key] = torch.stack([item[key] for item in batch])
            
        # [Case 2] ìˆ«ì(int, float)ì¸ ê²½ìš° -> Try Tensor conversion
        elif isinstance(sample, (int, float)):
            try:
                # ì¼ë‹¨ í…ì„œ ë³€í™˜ì„ ì‹œë„í•©ë‹ˆë‹¤.
                output[key] = torch.tensor([item[key] for item in batch])
            except (ValueError, TypeError, RuntimeError):
                # ì•—! ì¤‘ê°„ì— ë¬¸ìì—´ì´ë‚˜ Noneì´ ì„ì—¬ìˆì–´ì„œ ì‹¤íŒ¨í–ˆë„¤ìš”.
                # ê·¸ëŸ¬ë©´ ê·¸ëƒ¥ ì•ˆì „í•˜ê²Œ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
                output[key] = [item[key] for item in batch]
            
        # [Case 3] ê·¸ ì™¸ (ë¬¸ìì—´ ë“±) -> List
        else:
            output[key] = [item[key] for item in batch]
            
    return output