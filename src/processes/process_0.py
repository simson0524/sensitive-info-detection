# src/processes/process_0.py

import torch
from torch.utils.data import DataLoader
from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split

# Modules
from src.modules.ner_preprocessor import NerPreprocessor
from src.models.ner_roberta import RobertaNerModel

# Utils
from src.utils.common import set_seed
from src.utils.logger import setup_experiment_logger

def run_process_0(config: dict) -> dict:
    """
    [Process 0] í•™ìŠµ í™˜ê²½ ë° ê°ì²´ ì´ˆê¸°í™” (Setup Phase)
    - ë‹¨ì¼ ë°ì´í„° ë””ë ‰í† ë¦¬ ë¡œë“œ -> Train/Valid ìë™ ë¶„í• 
    - ë°ì´í„°ì…‹, ëª¨ë¸, ì˜µí‹°ë§ˆì´ì € ìƒì„±
    """
    # 1. ì„¤ì • ë° ë¡œê±°
    exp_conf = config['experiment']
    train_conf = config['train']
    path_conf = config['path']
    experiment_code = exp_conf['experiment_code']
    
    logger = setup_experiment_logger(experiment_code, path_conf['log_dir'])
    logger.info(f"ğŸ› ï¸ [Process 0] Initializing Experiment: {experiment_code}")

    # ì‹œë“œ ê³ ì • (ë°ì´í„° ë¶„í• ì˜ ì¬í˜„ì„±ì„ ìœ„í•´ ë§¤ìš° ì¤‘ìš”)
    seed = train_conf.get('seed', 42)
    set_seed(seed)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # 2. ì „ì²˜ë¦¬ê¸° ë° ë°ì´í„°ì…‹ ìƒì„±
    logger.info("Step 1: Loading Data & Splitting Train/Valid...")
    tokenizer = AutoTokenizer.from_pretrained(train_conf['model_name'])
    
    # 2-1. Preprocessor ì´ˆê¸°í™”
    preprocessor = NerPreprocessor(
        tokenizer=tokenizer, 
        max_len=train_conf['max_len'], 
        label2id=train_conf['label_map']
    )
    
    # 2-2. ì „ì²´ Raw Data ë¡œë“œ (ë‹¨ì¼ ë””ë ‰í† ë¦¬)
    # config['path']['data_dir']ì— ëª¨ë“  json íŒŒì¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    all_samples, all_annos = preprocessor.load_data(path_conf['data_dir'])
    
    total_count = len(all_samples)
    if total_count == 0:
        raise ValueError(f"No data found in {path_conf['data_dir']}")

    # 2-3. Train / Valid ìë™ ë¶„í• 
    # validation_split ì„¤ì •ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 0.2 (20%) ì‚¬ìš©
    val_ratio = train_conf.get('validation_split', 0.2)
    
    # ìƒ˜í”Œ ID(í‚¤)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
    all_ids = list(all_samples.keys())
    train_ids, valid_ids = train_test_split(
        all_ids, 
        test_size=val_ratio, 
        random_state=seed, 
        shuffle=True
    )
    
    # IDë¥¼ ì´ìš©í•´ ë”•ì…”ë„ˆë¦¬ ì¬êµ¬ì„±
    train_samples = {uid: all_samples[uid] for uid in train_ids}
    train_annos = {uid: all_annos[uid] for uid in train_ids}
    
    valid_samples = {uid: all_samples[uid] for uid in valid_ids}
    valid_annos = {uid: all_annos[uid] for uid in valid_ids}

    logger.info(f"Data Split: Total({total_count}) -> Train({len(train_ids)}), Valid({len(valid_ids)})")

    # 2-4. Dataset ìƒì„±
    data_category = exp_conf.get('data_category', 'personal_data')
    
    logger.info("Creating Train Dataset...")
    train_dataset = preprocessor.create_dataset(train_samples, train_annos, data_category=data_category)
    
    logger.info("Creating Valid Dataset...")
    valid_dataset = preprocessor.create_dataset(valid_samples, valid_annos, data_category=data_category)
    
    # 2-5. DataLoader ìƒì„±
    train_loader = DataLoader(train_dataset, batch_size=train_conf['batch_size'], shuffle=True)
    valid_loader = DataLoader(valid_dataset, batch_size=train_conf['batch_size'], shuffle=False)

    # 3. ëª¨ë¸ ë° í•™ìŠµ ë„êµ¬ ì´ˆê¸°í™”
    logger.info("Step 2: Building Model & Optimizer...")
    
    encoder = AutoModel.from_pretrained(train_conf['model_name'])
    num_labels = len(preprocessor.ner_label2id)
    
    model = RobertaNerModel(
        encoder=encoder,
        num_classes=num_labels,
        use_focal=train_conf.get('use_focal', False)
    ).to(device)

    optimizer = AdamW(model.parameters(), lr=float(train_conf['learning_rate']))
    
    total_steps = len(train_loader) * train_conf['epochs']
    scheduler = get_linear_schedule_with_warmup(
        optimizer, 
        num_warmup_steps=int(total_steps * 0.1), 
        num_training_steps=total_steps
    )

    logger.info("âœ… [Process 0] Setup Completed.")

    # 4. Context ë°˜í™˜
    context = {
        "experiment_code": experiment_code,
        "device": device,
        "model": model,
        "optimizer": optimizer,
        "scheduler": scheduler,
        "train_loader": train_loader,
        "valid_loader": valid_loader,
        "preprocessor": preprocessor,
        "train_dataset": train_dataset,
        "valid_dataset": valid_dataset
    }
    
    return context