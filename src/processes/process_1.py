# src/processes/process_1.py

import torch
import os
import logging
from datetime import datetime

# 1. Modules: í•™ìŠµê³¼ ê²€ì¦ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆ
from src.modules.ner_trainer import Trainer
from src.modules.ner_evaluator import Evaluator

# 2. Database: DB ì—°ê²° ë° CRUD ìœ í‹¸ë¦¬í‹°
from src.database.connection import db_manager
from src.database import crud

# 3. Utils: ì‹œê°í™” ë° íŒŒì¼ ì‹œìŠ¤í…œ ê´€ë ¨ ë„êµ¬
from src.utils.visualizer import plot_loss_graph
from src.utils.common import ensure_dir

def run_process_1(config: dict, context: dict):
    """
    [Process 1] ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦ ë£¨í”„ (Execution Phase)
    
    Process 0ì—ì„œ ì¤€ë¹„ëœ ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì„ ë°›ì•„ ì‹¤ì œ í•™ìŠµ(Train)ê³¼ ê²€ì¦(Valid)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ë§¤ Epochë§ˆë‹¤ ê²°ê³¼ ì§€í‘œë¥¼ DBì— ì €ì¥í•˜ê³ , ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        config (dict): ì„¤ì • íŒŒì¼ ë‚´ìš© (experiment_config.yaml)
        context (dict): Process 0ì—ì„œ ìƒì„±ëœ ê°ì²´ë“¤ (ëª¨ë¸, ì˜µí‹°ë§ˆì´ì €, ë°ì´í„°ë¡œë” ë“±)

    Returns:
        dict: í•™ìŠµëœ ëª¨ë¸ì´ í¬í•¨ëœ ê°±ì‹ ëœ Context
    """
    
    # ==============================================================================
    # [Step 1] Context Unpacking & Setup (ì¤€ë¹„ ë‹¨ê³„)
    # ==============================================================================
    # Process 0ì—ì„œ ë„˜ì–´ì˜¨ ê°ì²´ë“¤ì„ ì‚¬ìš©í•˜ê¸° ì¢‹ê²Œ ë³€ìˆ˜ì— í• ë‹¹í•©ë‹ˆë‹¤.
    experiment_code = context['experiment_code']
    device = context['device']
    model = context['model']
    optimizer = context['optimizer']
    scheduler = context['scheduler']
    train_loader = context['train_loader']
    valid_loader = context['valid_loader']
    preprocessor = context['preprocessor'] # í† í¬ë‚˜ì´ì €ì™€ ë¼ë²¨ë§µì„ í¬í•¨í•˜ê³  ìˆìŒ

    train_conf = config['train']
    path_conf = config['path']

    # ë¡œê±° ì„¤ì •: run_experiment.pyì—ì„œ ìƒì„±ëœ ë¡œê±°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    logger = logging.getLogger(experiment_code)
    logger.info(f"ğŸš€ [Process 1] Start Training Loop for {experiment_code}")

    # ==============================================================================
    # [Step 2] Worker ëª¨ë“ˆ ì´ˆê¸°í™”
    # ==============================================================================
    # Trainer: í•™ìŠµ ë°ì´í„°ì…‹ì„ ìˆœíšŒí•˜ë©° ì—­ì „íŒŒ(Backprop)ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê°ì²´
    trainer = Trainer(model, optimizer, scheduler, device)
    
    # Evaluator: ê²€ì¦ ë°ì´í„°ì…‹ì„ ìˆœíšŒí•˜ë©° ë©”íŠ¸ë¦­ ê³„ì‚° ë° ì˜¤ë‹µ ë…¸íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ê°ì²´
    evaluator = Evaluator(
        model, 
        device, 
        preprocessor.tokenizer, 
        preprocessor.ner_id2label # ID(0,1..)ë¥¼ ë¼ë²¨(O, B-PER..)ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ í•„ìš”
    )

    # ==============================================================================
    # [Step 3] í•™ìŠµ ë£¨í”„ (Training Loop)
    # ==============================================================================
    # ìµœê³  ì„±ëŠ¥ ê¸°ë¡ì„ ì¶”ì í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”
    best_f1 = 0.0
    min_valid_loss = float('inf')
    best_f1_epoch = -1
    min_loss_epoch = -1

    # ê·¸ë˜í”„ ê·¸ë¦¬ê¸° ìœ„í•œ ë¦¬ìŠ¤íŠ¸
    train_losses = []
    valid_losses = []
    
    # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ ìƒì„±: outputs/checkpoints/{experiment_code}/
    ckpt_save_dir = os.path.join(path_conf['checkpoint_dir'], experiment_code)
    ensure_dir(ckpt_save_dir)

    # DB ì„¸ì…˜ ì‹œì‘ (ë£¨í”„ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì²˜ë¦¬)
    with db_manager.get_db() as session:
        for epoch in range(1, train_conf['epochs'] + 1):
            logger.info(f"=== Epoch {epoch}/{train_conf['epochs']} ===")
            
            # -----------------------------------------------------------
            # 3-1. í•™ìŠµ (Train Phase)
            # -----------------------------------------------------------
            # Trainerê°€ 1 Epoch í•™ìŠµì„ ìˆ˜í–‰í•˜ê³  Lossì™€ ì†Œìš”ì‹œê°„ì„ ë°˜í™˜
            train_result = trainer.train_epoch(train_loader, epoch)
            train_losses.append(train_result['loss'])
            
            # -----------------------------------------------------------
            # 3-2. ê²€ì¦ (Validation Phase)
            # -----------------------------------------------------------
            # Evaluatorê°€ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³  ë©”íŠ¸ë¦­ê³¼ ìƒì„¸ ë¡œê·¸(ì˜¤ë‹µ í¬í•¨)ë¥¼ ë°˜í™˜
            # mode='valid': Ground Truthì™€ ë¹„êµí•˜ì—¬ ì •ë‹µ ì—¬ë¶€ë¥¼ íŒë‹¨í•¨
            valid_result = evaluator.evaluate(valid_loader, mode="valid")
            
            valid_metrics = valid_result['metrics'] # Loss, F1, Precision, Recall, Confusion Matrix
            valid_logs = valid_result['logs']       # ë¬¸ì¥ë³„ ìƒì„¸ ì¶”ë¡  ê²°ê³¼ (DB ì €ì¥ìš© List[Dict])
            valid_losses.append(valid_metrics['loss'])
            
            # -----------------------------------------------------------
            # 3-3. ê²°ê³¼ í†µí•© ë° DB ì €ì¥ (Epoch ë‹¨ìœ„ ìš”ì•½)
            # -----------------------------------------------------------
            
            # (1) ëª¨ë“  ì§€í‘œë¥¼ í•˜ë‚˜ì˜ ë”•ì…”ë„ˆë¦¬ë¡œ í†µí•© (JSONB ì»¬ëŸ¼ì— ì €ì¥ë  ë°ì´í„°)
            epoch_all_metrics = {
                "train_loss": train_result['loss'],
                "train_time": train_result['duration'],
                "valid_loss": valid_metrics['loss'],
                "valid_precision": valid_metrics['precision'],
                "valid_recall": valid_metrics['recall'],
                "valid_f1": valid_metrics['f1'],
                "valid_time": valid_result['duration'],
                "confusion_matrix": valid_metrics['confusion_matrix'] # List[List[int]] í˜•íƒœ
            }
            
            # (2) experiment_process_results í…Œì´ë¸”ì— ì €ì¥ (1 Row per Epoch)
            # ì´ í…Œì´ë¸”ì€ ì‹¤í—˜ì˜ ì‹œê³„ì—´ì  ë³€í™”(Loss ê°ì†Œ ë“±)ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
            crud.create_process_result(session, {
                "experiment_code": experiment_code,
                "process_code": "process_1", # í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì‹ë³„ì
                "process_epoch": epoch,
                
                # ì‹œê°„ ì •ë³´: Train + Valid ì „ì²´ ì†Œìš” ì‹œê°„
                "process_start_time": train_result['start_time'], 
                "process_end_time": valid_result['end_time'], 
                "process_duration": train_result['duration'] + valid_result['duration'],
                
                # í•µì‹¬: ëª¨ë“  ì§€í‘œê°€ ë‹´ê¸´ JSON
                "process_results": epoch_all_metrics 
            })
            
            logger.info(f"Epoch {epoch} Result Saved. (Train Loss: {train_result['loss']:.4f} | Valid F1: {valid_metrics['f1']:.4f})")

            # (3) ë¬¸ì¥ ë‹¨ìœ„ ì¶”ë¡  ê²°ê³¼ DB ì €ì¥ (Bulk Insert)
            # ì˜¤ë‹µ ë¶„ì„ì„ ìœ„í•´ ëª¨ë“  ê²€ì¦ ë¬¸ì¥ì˜ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
            # FK ì •ë³´(ì‹¤í—˜ì½”ë“œ, í”„ë¡œì„¸ìŠ¤ì½”ë“œ, ì—í­)ë¥¼ ë¡œê·¸ ë”•ì…”ë„ˆë¦¬ì— ì£¼ì…
            for log in valid_logs:
                log['experiment_code'] = experiment_code
                log['process_code'] = "process_1"
                log['process_epoch'] = epoch
            
            # ëŒ€ëŸ‰ ë°ì´í„° ì‚½ì… (ì†ë„ ìµœì í™”)
            crud.bulk_insert_inference_sentences(session, valid_logs)
            logger.info(f"Saved {len(valid_logs)} inference logs to DB.")

            # -----------------------------------------------------------
            # 3-4. ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (Model Checkpoint)
            # -----------------------------------------------------------
            # ëª¨ë“  Epochì˜ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤ (ë‚˜ì¤‘ì— ë¶„ì„í•˜ê±°ë‚˜ Resume í•  ë•Œ ì‚¬ìš©)
            save_name = f"epoch_{epoch}.pt"
            save_path = os.path.join(ckpt_save_dir, save_name)
            torch.save(model.state_dict(), save_path)
            
            # Best F1 Score ê°±ì‹  ì—¬ë¶€ í™•ì¸
            if valid_metrics['f1'] > best_f1:
                best_f1 = valid_metrics['f1']
                best_f1_epoch = epoch
                logger.info(f"âœ¨ Current Best F1: {best_f1:.4f} (Epoch {epoch})")
            
            # Min Loss ê°±ì‹  ì—¬ë¶€ í™•ì¸ (Overfitting ê°ì§€ìš©)
            if valid_metrics['loss'] < min_valid_loss:
                min_valid_loss = valid_metrics['loss']
                min_loss_epoch = epoch
                logger.info(f"ğŸ“‰ Current Min Loss: {min_valid_loss:.4f} (Epoch {epoch})")

        # ==============================================================================
        # [Step 4] ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ (DB Update)
        # ==============================================================================
        # í•™ìŠµ ì¢…ë£Œ í›„, ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ ëª¨ë¸ì˜ ê²½ë¡œë¥¼ Experiment í…Œì´ë¸”ì— ê¸°ë¡í•©ë‹ˆë‹¤.
        # ì¶”í›„ Inference ë‹¨ê³„ì—ì„œ ì´ ê²½ë¡œë¥¼ ì°¸ì¡°í•˜ì—¬ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        
        exp_obj = crud.get_experiment(session, experiment_code)
        if exp_obj:
            current_config = exp_obj.experiment_config or {}
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê²½ë¡œ êµ¬ì„±
            best_f1_path = os.path.join(ckpt_save_dir, f"epoch_{best_f1_epoch}.pt")
            min_loss_path = os.path.join(ckpt_save_dir, f"epoch_{min_loss_epoch}.pt")
            
            # Config JSON ì—…ë°ì´íŠ¸
            current_config['best_model_f1_path'] = best_f1_path
            current_config['best_model_loss_path'] = min_loss_path
            current_config['best_f1_score'] = best_f1
            current_config['min_valid_loss'] = min_valid_loss
            
            crud.update_experiment(session, experiment_code, {
                "experiment_config": current_config,
            })
            logger.info(f"âœ… Experiment Meta Updated. (Best F1 Epoch: {best_f1_epoch})")

    # ==============================================================================
    # [Step 5] ë§ˆë¬´ë¦¬ ë° ì‹œê°í™” (Finalize)
    # ==============================================================================
    # í•™ìŠµ ì¢…ë£Œ í›„ Loss ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ì„œ ì €ì¥í•©ë‹ˆë‹¤.
    save_dir = os.path.join(path_conf['log_dir'], experiment_code)
    
    plot_loss_graph(
        train_losses, 
        valid_losses, 
        save_dir, 
        experiment_code
    )
    
    logger.info("[Process 1] Process Completed Successfully.")
    
    # í•™ìŠµëœ ëª¨ë¸ ê°ì²´ë¥¼ í¬í•¨í•˜ì—¬ Context ë°˜í™˜
    return context